{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "fixed_size       = tuple((64, 64))\n",
    "bins             = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv\n",
    "def color_Moments(img):\n",
    "    img=rgb2hsv(img)\n",
    "    R=img[:,:,0]\n",
    "    G=img[:,:,1]\n",
    "    B=img[:,:,2]\n",
    "    colorFeatures=[np.mean(R[:]),np.std(R[:]),np.mean(G[:]),np.std(G[:]),np.mean(B[:]),np.std(B[:])]\n",
    "    colorFeatures=colorFeatures/np.mean(colorFeatures)\n",
    "    return colorFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_HSV(image, mask=None):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([np.uint8(image)], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments \n",
    "# forme\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    # return the result\n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "def glcm_props(patch):\n",
    "    lf = []\n",
    "    props = ['dissimilarity', 'contrast', 'homogeneity', 'energy', 'correlation']\n",
    "    patch=np.array(rgb2gray(patch), int)\n",
    "    # left nearest neighbor\n",
    "    glcm = feature.greycomatrix(patch, [1], [0], 256, symmetric=True, normed=True)\n",
    "    for f in props:\n",
    "        lf.append( feature.greycoprops(glcm, f)[0,0] )\n",
    "    # upper nearest neighbor\n",
    "    glcm = feature.greycomatrix(patch, [1], [np.pi/2], 256, symmetric=True, normed=True)\n",
    "    for f in props:\n",
    "        lf.append( feature.greycoprops(glcm, f)[0,0] )\n",
    "    return np.asarray(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calendula', 'Coquelicot', \"Feuille d'olivier\", 'Feuilles de figuier', 'Glebionis coronaria', 'Jasmin', 'La verveine', 'Menthe', 'Ortie', 'Persil', 'Romarin', 'Sauge', 'Thym', 'lavande']\n"
     ]
    }
   ],
   "source": [
    "# get the training labels\n",
    "train_path=\"../train_dataset\"\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# sort the training labels\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "\n",
    "# empty lists to hold feature vectors and labels\n",
    "global_features = []\n",
    "labels          = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendula --> 419\n",
      "[STATUS] processed folder: Calendula\n",
      "Coquelicot --> 637\n",
      "[STATUS] processed folder: Coquelicot\n",
      "Feuille d'olivier --> 463\n",
      "[STATUS] processed folder: Feuille d'olivier\n",
      "Feuilles de figuier --> 480\n",
      "[STATUS] processed folder: Feuilles de figuier\n",
      "Glebionis coronaria --> 522\n",
      "[STATUS] processed folder: Glebionis coronaria\n",
      "Jasmin --> 501\n",
      "[STATUS] processed folder: Jasmin\n",
      "La verveine --> 547\n",
      "[STATUS] processed folder: La verveine\n",
      "Menthe --> 508\n",
      "[STATUS] processed folder: Menthe\n",
      "Ortie --> 587\n",
      "[STATUS] processed folder: Ortie\n",
      "Persil --> 544\n",
      "[STATUS] processed folder: Persil\n",
      "Romarin --> 498\n",
      "[STATUS] processed folder: Romarin\n",
      "Sauge --> 521\n",
      "[STATUS] processed folder: Sauge\n",
      "Thym --> 575\n",
      "[STATUS] processed folder: Thym\n",
      "lavande --> 619\n",
      "[STATUS] processed folder: lavande\n",
      "[STATUS] completed Global Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "# loop over the training data sub-folders\n",
    "for training_name in train_labels:\n",
    "    # join the training data path and each species training folder\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    nb_img=len(os.listdir(dir))\n",
    "    # get the current training label\n",
    "    current_label = training_name\n",
    "    print(current_label,\"-->\",nb_img)\n",
    "    # loop over the images in each sub-folder\n",
    "    for elem in os.listdir(dir):\n",
    "        # get the image file name\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(dir+\"/\"+elem)\n",
    "        try:\n",
    "            image = cv2.resize(image, fixed_size)\n",
    "        except:\n",
    "            print(elem)\n",
    "        ####################################\n",
    "        # Global Feature extraction\n",
    "        ####################################\n",
    "        color_moment=color_Moments(image)\n",
    "        fv_hu_moments = fd_hu_moments(image)\n",
    "#         fv_haralick   = fd_haralick(image)\n",
    "        histogram=fd_HSV(image)\n",
    "        glcm=glcm_props(image)\n",
    "        ###################################\n",
    "        # Concatenate global features\n",
    "        ###################################\n",
    "        global_feature = np.hstack([color_moment,fv_hu_moments,histogram,glcm])\n",
    "        # update the list of labels and feature vectors\n",
    "        labels.append(current_label)\n",
    "        global_features.append(global_feature)\n",
    "        \n",
    "\n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "\n",
    "print(\"[STATUS] completed Global Feature Extraction...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7421, 535)\n",
      "(7421,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# joblib.dump(global_features,\"features.pkl\",compress=True)\n",
    "# joblib.dump(labels,\"labels.pkl\",compress=True)\n",
    "\n",
    "features    = np.array(joblib.load(\"features.pkl\"))\n",
    "labels  = np.array(joblib.load(\"labels.pkl\"))\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import warnings\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "num_trees = 500\n",
    "test_size = 0.10\n",
    "seed      = 9\n",
    "scoring    = \"accuracy\"\n",
    "# create all the machine learning models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "# models.append(('SVM', SVC(random_state=seed)))\n",
    "models.append(('SVM_2', svm.SVC(kernel='rbf', C=7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (6678, 535)\n",
      "Test data   : (743, 535)\n",
      "Train labels: (6678,)\n",
      "Test labels : (743,)\n"
     ]
    }
   ],
   "source": [
    "# split the training and testing data\n",
    "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(features),\n",
    "                                                                                          np.array(labels),\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          random_state=seed)\n",
    "\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.505243 (0.023106)\n",
      "LDA: 0.511085 (0.021213)\n",
      "KNN: 0.126381 (0.011424)\n",
      "CART: 0.553319 (0.021721)\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross validation\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Machine Learning algorithm comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n",
    "# os.system(\"shutdown /s /t 1\")shutdown your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7725437415881561\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# create the model - Random Forests\n",
    "clf  = RandomForestClassifier(n_estimators=500, random_state=seed)\n",
    "# clf = DecisionTreeClassifier(random_state=seed)\n",
    "# clf = svm.SVC(kernel='rbf', C=100)\n",
    "# fit the training data to the model\n",
    "clf.fit(trainDataGlobal, trainLabelsGlobal)\n",
    "with open(\"model.pkl\",\"wb\")as file:\n",
    "    pickle.dump(clf,file)\n",
    "    file.close()\n",
    "b=clf.predict(testDataGlobal).tolist()\n",
    "a=testLabelsGlobal\n",
    "accuracy = len([a[i] for i in range(0, len(a)) if a[i] == b[i]]) / len(a)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998502545672358\n"
     ]
    }
   ],
   "source": [
    "#training accuraccy\n",
    "import pickle \n",
    "with open(\"model.pkl\",\"rb\")as file:\n",
    "    clf= pickle.load(file)\n",
    "    \n",
    "list2=clf.predict(trainDataGlobal).tolist()\n",
    "\n",
    "b = list2   # predicted labels\n",
    "a=trainLabelsGlobal\n",
    "\n",
    "accuracy = len([a[i] for i in range(0, len(a)) if a[i] == b[i]]) / len(a)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "with open(\"model.pkl\",\"rb\")as file:\n",
    "    clf=pickle.load(file)\n",
    "\n",
    "for image in os.listdir(\"test\"):\n",
    "    # read the image\n",
    "    image = cv2.imread(\"test/\"+image)\n",
    "    # resize the image\n",
    "    image = cv2.resize(image, fixed_size)\n",
    "    color_moment=color_Moments(image)\n",
    "    fv_hu_moments = fd_hu_moments(image)\n",
    "    fv_haralick   = fd_haralick(image)\n",
    "    histogram=fd_HSV(image)\n",
    "    glcm=glcm_props(image)\n",
    "    ###################################\n",
    "    # Concatenate global features\n",
    "    ###################################\n",
    "    global_feature = np.hstack([color_moment,fv_hu_moments,fv_haralick,histogram,glcm])\n",
    "    global_feature = np.array(global_feature).reshape(-1,1)\n",
    "    print(global_feature.shape)\n",
    "     # scale features in the range (0-1)\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     rescaled_feature = scaler.fit_transform(global_feature)\n",
    "    # predict label of test image\n",
    "    prediction = clf.predict(global_feature.reshape(1,-1))[0]\n",
    "    # show predicted label on image\n",
    "    cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    # display the output image\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
